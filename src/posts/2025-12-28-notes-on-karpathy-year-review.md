---
title: "The Year of Claude Code"
date: "2025-12-28"
---
I agree with [Karpathy](https://karpathy.bearblog.dev/year-in-review-2025/) on all but the order. Claude code is undoubtedly 1st on the list. 

> the LLMs spontaneously develop strategies that look like "reasoning" to humans

Note the “look like”

> Also unique to this new stage, we got a whole new knob (and and associated scaling law) to control capability as a function of test time compute by generating longer reasoning traces and increasing "thinking time".

 

> As verifiable domains allow for RLVR, LLMs "spike" in capability in the vicinity of these domains and overall display amusingly jagged performance characteristics - they are at the same time a genius polymath and a confused and cognitively challenged grade schooler, seconds away from getting tricked by a jailbreak to exfiltrate your data.

​

> Related to all this is my general apathy and loss of trust in benchmarks in 2025.

​benchmarks are like GMAT scores for business school. You got to take the test and cross the threshold to enter the candidate pool. But beyond that, it doesn’t matter how high you score for anything else. 



> The core issue is that benchmarks are almost by construction verifiable environments and are therefore immediately susceptible to RLVR and weaker forms of it via synthetic data generation.

​I think this is a good point for LLMs in general. The generative powers of ML models have crossed the threshold of single yes or no answer, but our evaluation methods have not adapted yet. And they may never do. Is it possible that the effort gap between generation and evaluation shrinks as the models get more powerful? It definitely feels that way. 

> deployed professionals in specific verticals by supplying private data, sensors and actuators and feedback loops.

​I think that’s right; and I think it will apply to robotics too. You won’t see robots running your household, but you will see a lot of robot arms bolted on the wall of manufacturing assembly lines.

> And while agent swarms running in the cloud feels like the "AGI endgame", we live in an intermediate and slow enough takeoff world of jagged capabilities that it makes more sense to simply run the agents on the computer, hand in hand with developers and their specific setup. CC got this order of precedence correct and packaged it into a beautiful, minimal, compelling CLI form factor that changed what AI looks like

​True. Claude Code was the defining moment of 2025. 

> it empowers trained professionals to write a lot more (vibe coded) software that would otherwise never be written

This is what I am most excited about. And it’s also the reason why fewer jobs will be lost than some fear. AI enables us to write software that would have not been written otherwise. It’s not automating us, it’s enhancing us. Of course there are tasks that will be automated completely, but the amount of human activity that is fully automatable by AI seems to me to be in line with previous technology leaps. Doctorow gave a very clear argument on this recently, here are my notes [[2025-12-21-cory-doctorow-s-talk]].
​

