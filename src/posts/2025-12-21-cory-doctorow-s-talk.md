---
title: "Cory Doctorow's Talk"
date: "2025-12-21"
---

I recently read [Pluralistic: The Reverse-Centaur’s Guide to Criticizing AI (05 Dec 2025) by Cory Doctorow](https://pluralistic.net/2025/12/05/pop-that-bubble/) 

Really smart critic of AI by Cory Doctorow. Worth reading. 

CD does a great job capturing some of the anxieties stemming from what AI tools are capable of, both good and bad. 

> There are lots of AI tools that are potentially very centaur-like, but my thesis is that these tools are created and funded for the express purpose of creating reverse-centaurs, which is something none of us want to be.

The bad scenario is that AI takes over all human jobs. CD introduces the even worse scenario (and maybe even more probable?), of AI taking over most of the jobs but still requiring humans for the boring menial parts. Which he describes as reverse-centaur, to contrast it with the positive outcome of humans using AI to augment our capabilities ("centaur-like"). 

He also argues with clarity about some emerging limitation of AI agents. CD essentially says that AI will always fall short of automating 100% of the work. And more importantly, he argues that even if AI automates 90%, the 10% that remains will be critical a will require skilled humans involved. In other words, you will need experience programmer for the last mile and without them that you would not be able to use even the 90% that’s supposedly done. 

> "Automation blindness is the Achilles' heel of "humans in the loop."
> Earlier, I alluded to "automation blindness, "the physical impossibility of remaining vigilant for things that rarely occur. This is why TSA agents are incredibly good at spotting water bottles."

>“For AI to be valuable, it has to replace high-wage workers, and those are precisely the experienced workers, with process knowledge, and hard-won intuition, who might spot some of those statistically camouflaged AI errors.”

This is an issue with AI that anyone oughts to take seriously. Although there are ways to mitigate it (robust testing suites) there is no actual solution yet. That's why I am personally excited about AI augmenting humans instead of automating them: instead of replacing coders think of giving coding capabilities to more people who wouldn't be able to code before. If you do that in an *order of magnitude more people* that previously possible, the world can really change. (I hope for the better)

CD gives a good example of what can go wrong. The example he gives is about AI assisted coding but I think the idea applies more broadly

> Now, because the AI is a statistical inference engine, because all it can do is predict what word will come next based on all the words that have been typed in the past, it will "hallucinate" a library called lib.pdf.text.parsing. And the thing is, malicious hackers know that the AI will make this error, so they will go out and create a library with the predictable, hallucinated name, and that library will get automatically sucked into your program, and it will do things like steal user data or try and penetrate other computers on the same network.

​
I look forward to CD's book. 
## References

[Pluralistic: The Reverse-Centaur’s Guide to Criticizing AI (05 Dec 2025) by Cory Doctorow](https://pluralistic.net/2025/12/05/pop-that-bubble/) 
